{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/llgrid/pkg/anaconda/anaconda3-2022b/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load traffic data\n",
    "data = pd.read_csv(\"data.csv\", index_col=0)\n",
    "agg_mat_df = pd.read_csv(\"agg_mat.csv\", index_col=0)\n",
    "\n",
    "maximum = np.max(data.values)\n",
    "data_scaled = (data / maximum).values\n",
    "\n",
    "seed = 0 \n",
    "\n",
    "def set_seeds(seed): \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # if using nvidia gpu\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "\n",
    "set_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 555)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_series = data.shape[1] \n",
    "n_total = data.shape[0]\n",
    "n_train = 145\n",
    "context_window = 5\n",
    "n_val = 30\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wmape(actual_values, forecasted_values):\n",
    "    # compute wMAPE metric\n",
    "    n = len(actual_values)\n",
    "    num = np.sum(np.abs(actual_values - forecasted_values))\n",
    "    den = np.sum(np.abs(actual_values))\n",
    "    wmape = num/den\n",
    "    return wmape\n",
    "\n",
    "def calculate_RMSE(actual_values, forecasted_values): \n",
    "    # compute RMSE metric\n",
    "    squared_errors = (actual_values - forecasted_values) ** 2\n",
    "    mean_squared_error = np.mean(squared_errors)\n",
    "    rmse = np.sqrt(mean_squared_error)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-50.,   0.,  50., 100., 150., 200., 250.]),\n",
       " [Text(-50.0, 0, 'âˆ’50'),\n",
       "  Text(0.0, 0, '0'),\n",
       "  Text(50.0, 0, '50'),\n",
       "  Text(100.0, 0, '100'),\n",
       "  Text(150.0, 0, '150'),\n",
       "  Text(200.0, 0, '200'),\n",
       "  Text(250.0, 0, '250')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_scaled[:,0])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(dataset, range_, context_window): \n",
    "    # produces X_data and y_data tensors given the dataset \n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    for i in range_:\n",
    "        X = dataset[i:i+context_window,:].T.flatten()\n",
    "        X_data.append(X)\n",
    "\n",
    "        y = dataset[i+context_window:i+context_window+1,:].T.flatten()\n",
    "        y_data.append(y)\n",
    "\n",
    "    return torch.tensor(X_data, dtype=float), torch.tensor(y_data, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Tourism(Dataset):\n",
    "    def __init__(self, root_path, flag='train', data_path='data.csv', context_window=5, n_train=n_train, n_val=50, seq_len=n_train-context_window):\n",
    "        \n",
    "        # init\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.context_window=context_window\n",
    "        self.n_train = n_train\n",
    "        self.n_val = n_val\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[flag]\n",
    "\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path,\n",
    "                                          self.data_path), index_col=0)\n",
    "        maximum = np.max(df_raw.values)\n",
    "        data = (df_raw / maximum).values\n",
    "        \n",
    "        X_data = []\n",
    "        y_data = []\n",
    "\n",
    "        if self.set_type == 0: \n",
    "            data_range = range(self.n_train)\n",
    "        elif self.set_type == 1: \n",
    "            data_range = range(self.n_train, self.n_train + self.n_val)\n",
    "        else: \n",
    "            data_range = range(self.n_train + self.n_val, self.data.shape[0] - self.context_window)\n",
    "\n",
    "        for i in data_range:\n",
    "            X = data[i:i+self.context_window,:].T.flatten()\n",
    "            X_data.append(np.array(X))\n",
    "\n",
    "            y = data[i+self.context_window:i+self.context_window+1,:].T.flatten()\n",
    "            y_data.append(np.array(y))\n",
    "            \n",
    "        print(len(X_data))\n",
    "\n",
    "        self.X = torch.tensor(X_data, dtype=float)\n",
    "        self.y = torch.tensor(y_data, dtype=float)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index:index + self.seq_len, :]\n",
    "        y = self.y[index:index + self.seq_len]\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - context_window - self.seq_len + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/slurm_tmp/26011002.0.0/ipykernel_2102632/3728941026.py:43: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  self.X = torch.tensor(X_data, dtype=float)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset_Tourism('/home/gridsan/mhensgen/tourism/', seq_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([145, 2775])\n",
      "torch.Size([30, 2775])\n",
      "torch.Size([48, 2775])\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = make_data(data_scaled, range(n_train), context_window)\n",
    "X_val, y_val = make_data(data_scaled, range(n_train, n_train+n_val), context_window)\n",
    "X_test, y_test = make_data(data_scaled, range(n_train + n_val,n_total - context_window), context_window)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAAHol</th>\n",
       "      <th>AAAVis</th>\n",
       "      <th>AAABus</th>\n",
       "      <th>AAAOth</th>\n",
       "      <th>AABHol</th>\n",
       "      <th>AABVis</th>\n",
       "      <th>AABBus</th>\n",
       "      <th>AABOth</th>\n",
       "      <th>ABAHol</th>\n",
       "      <th>ABAVis</th>\n",
       "      <th>...</th>\n",
       "      <th>GBBBus</th>\n",
       "      <th>GBBOth</th>\n",
       "      <th>GBCHol</th>\n",
       "      <th>GBCVis</th>\n",
       "      <th>GBCBus</th>\n",
       "      <th>GBCOth</th>\n",
       "      <th>GBDHol</th>\n",
       "      <th>GBDVis</th>\n",
       "      <th>GBDBus</th>\n",
       "      <th>GBDOth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TotalAll</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAll</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAll</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAll</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAll</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBCOth</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBDHol</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBDVis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBDBus</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBDOth</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555 rows Ã— 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AAAHol  AAAVis  AAABus  AAAOth  AABHol  AABVis  AABBus  AABOth  \\\n",
       "TotalAll     1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
       "AAll         1.0     1.0     1.0     1.0     1.0     1.0     1.0     1.0   \n",
       "BAll         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "CAll         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "DAll         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...          ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "GBCOth       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "GBDHol       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "GBDVis       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "GBDBus       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "GBDOth       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "          ABAHol  ABAVis  ...  GBBBus  GBBOth  GBCHol  GBCVis  GBCBus  GBCOth  \\\n",
       "TotalAll     1.0     1.0  ...     1.0     1.0     1.0     1.0     1.0     1.0   \n",
       "AAll         1.0     1.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "BAll         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "CAll         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "DAll         0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...          ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "GBCOth       0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     1.0   \n",
       "GBDHol       0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "GBDVis       0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "GBDBus       0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "GBDOth       0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "          GBDHol  GBDVis  GBDBus  GBDOth  \n",
       "TotalAll     1.0     1.0     1.0     1.0  \n",
       "AAll         0.0     0.0     0.0     0.0  \n",
       "BAll         0.0     0.0     0.0     0.0  \n",
       "CAll         0.0     0.0     0.0     0.0  \n",
       "DAll         0.0     0.0     0.0     0.0  \n",
       "...          ...     ...     ...     ...  \n",
       "GBCOth       0.0     0.0     0.0     0.0  \n",
       "GBDHol       1.0     0.0     0.0     0.0  \n",
       "GBDVis       0.0     1.0     0.0     0.0  \n",
       "GBDBus       0.0     0.0     1.0     0.0  \n",
       "GBDOth       0.0     0.0     0.0     1.0  \n",
       "\n",
       "[555 rows x 304 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "aggregation_mat = torch.tensor(np.append(np.zeros((agg_mat_df.shape[0], agg_mat_df.shape[0] - agg_mat_df.shape[1])), agg_mat_df, axis=1), dtype=float).to(device)\n",
    "S = agg_mat_df.values\n",
    "\n",
    "def coherency_loss(network): \n",
    "    # computes coherency on last layer of the network \n",
    "    repeated_bias = network.last_layer.bias.repeat(network.last_layer.weight.shape[0], 1)\n",
    "    return torch.norm(aggregation_mat @ network.last_layer.weight - network.last_layer.weight) + torch.norm(\n",
    "        aggregation_mat @ repeated_bias - repeated_bias) \n",
    "\n",
    "def coherency_metric(predictions):\n",
    "    # computes the actual coherency of predictions \n",
    "    return torch.norm(predictions.T - aggregation_mat @ predictions.T) / predictions.shape[1]\n",
    "\n",
    "def create_M(S): \n",
    "    # creates the projection matrix M given the aggregation matrix S\n",
    "    m, m_K = S.shape\n",
    "    m_agg = m-m_K\n",
    "\n",
    "    # The top `m_agg` rows of the matrix `S` give the aggregation constraint matrix.\n",
    "    S_agg = S[:m_agg, :]\n",
    "    A = np.hstack((np.eye(m_agg), -S_agg))\n",
    "\n",
    "    M = np.eye(m) - A.T @ np.linalg.pinv(A @ A.T) @ A  \n",
    "\n",
    "    return torch.from_numpy(M).float(), torch.from_numpy(A).float()\n",
    "\n",
    "\n",
    "M, A = create_M(S)\n",
    "\n",
    "def project_samples(y): \n",
    "    # project y using S (aggregation matrix )\n",
    "    # y should have shape n_samples x n_series\n",
    "    # y = y\n",
    "    # n_samples, n_series = y.shape\n",
    "    # eye = torch.eye(n_series).float()\n",
    "    # eye = eye.reshape((1, n_series, n_series))\n",
    "    # n_samples_eye = eye.repeat(n_samples, 1, 1)\n",
    "    # Q = 2*n_samples_eye\n",
    "    # G = -n_samples_eye\n",
    "    # p = -2*y\n",
    "    # b = torch.zeros((n_samples, A.shape[0])).float()\n",
    "    # h = torch.zeros((n_samples, n_series)).float()\n",
    "    # A_rep = A.repeat(n_samples, 1, 1)\n",
    "    # y_proj = QPFunction(verbose=False)(Q, p, G, h, A_rep, b)\n",
    "\n",
    "    return torch.matmul(y, M.double().to(device))\n",
    "\n",
    "\n",
    "def least_squares_loss(predictions): \n",
    "    # computes the projections and then takes least squares loss between predictions and projections \n",
    "    # predictions should have shape n_samples x n_series \n",
    "    # implements coherency loss from https://www.sciencedirect.com/science/article/pii/S0306261923008747#fig5\n",
    "    projections = project_samples(predictions)\n",
    "    error = predictions - projections \n",
    "    square_error = torch.square(error)\n",
    "    return torch.sum(square_error) / error.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 304)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmNet(nn.Module):\n",
    "    def __init__(self, n_series, context, should_project=False):\n",
    "        \"\"\"\n",
    "        n_series = number of time series we have\n",
    "        context = size of context window (how many samples back we are using to predict)\n",
    "        should_project: boolean determining if we use a projection before output for coherency\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        set_seeds(seed)\n",
    "        hidden_size = int(n_series * context / 2)\n",
    "        self.lstm =  nn.LSTM(input_size=n_series * context, hidden_size=hidden_size, dropout=0.2, num_layers=2, dtype=float)\n",
    "        self.last_layer = nn.Linear(hidden_size, n_series, dtype=float)\n",
    "        self.should_project = should_project\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size, dtype=float)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.relu(x)\n",
    "        x_3d = len(x.shape) >= 3\n",
    "        if x_3d: \n",
    "            x = x.transpose(1,2)\n",
    "        x = self.batch_norm(x)\n",
    "        if x_3d: \n",
    "            x = x.transpose(1,2)\n",
    "        out = self.last_layer(x)\n",
    "\n",
    "        if self.should_project: \n",
    "            out = project_samples(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "def train_net(n_epochs, batch_size=10, coherent=False, alpha=0, should_project=False, alpha_scaling=0, least_squares=False, scaling_increase_factor=0,\n",
    "               verbose=False, should_schedule=False, plot_loss=False, lr=0.001, max_grad_norm=10): \n",
    "    \"\"\"\n",
    "    trains an LSTMNet on the traffic dataset based on the given parameters\n",
    "    coherent: if true, uses coherent loss \n",
    "    alpha: the term we multiply the 'coherency_loss' by in calculating overall loss \n",
    "    should_project: if true, uses projection method \n",
    "    alpha_scaling: if a number, we will scale alpha by alpha_scaling * l1/l2. \n",
    "    essentially, we are setting l1 = l2*alpha, so the coherency will be weighted by 'alpha_scaling' in the loss\n",
    "    \"\"\"\n",
    "    # sets the number of epochs we train before updating alpha \n",
    "\n",
    "    update_alpha_epoch = 100\n",
    "\n",
    "    network = LstmNet(n_series, context_window, should_project=should_project)\n",
    "    network = network.to(device)\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False)\n",
    "\n",
    "    print('--- alpha {alpha} ---- lr  {lr}----'.format(alpha=alpha, lr=lr))\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "    if should_schedule: \n",
    "        if scaling_increase_factor > 0: \n",
    "            scheduler = MultiStepLR(optimizer, milestones=[i for i in range(update_alpha_epoch + 1, n_epochs, update_alpha_epoch)], gamma=1-scaling_increase_factor)\n",
    "        else: \n",
    "            scheduler = MultiStepLR(optimizer, milestones=[750, 1500, 2250], gamma=0.99)\n",
    "\n",
    "    losses = []\n",
    "    l1s = [] \n",
    "    l2s = []\n",
    "    validation_loss =[] \n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "        inputs, labels = next(iter(train_dataloader))\n",
    "        \n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device) \n",
    "\n",
    "        # print(inputs[0, :20, 0])\n",
    "        # print(labels[0, :20, 0]) \n",
    "        # print(X_train[:20, 0]) \n",
    "        # print(y_train[:20, 0]) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # add coherency network loss\n",
    "        if coherent: \n",
    "            l1 = criterion(outputs, labels) \n",
    "            l2 = coherency_loss(network)\n",
    "\n",
    "            l2s.append(l2.item())\n",
    "            l1s.append(l1.item())\n",
    "\n",
    "            loss = (l1 + alpha * l2)\n",
    "\n",
    "            if loss.isnan(): \n",
    "                print('---')\n",
    "                print(l1)\n",
    "                print(l1s[epoch-5:])\n",
    "                print(l2)\n",
    "                print(l2s[epoch-5:])\n",
    "\n",
    "            validation_loss.append((criterion(network(X_val.to(device)), y_val.to(device)) + alpha * l2).item())\n",
    "\n",
    "\n",
    "        # normal loss\n",
    "        else: \n",
    "            loss = criterion(outputs, labels)\n",
    "            validation_loss.append(criterion(network(X_val.to(device)), y_val.to(device)).item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(network.parameters(), max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if epoch % update_alpha_epoch == 0 and epoch > 0:   \n",
    "            if verbose:  \n",
    "                print(\"Epoch:\", epoch, \" Loss: \", np.mean(losses))\n",
    "                print(np.mean(np.array(l1s[epoch-update_alpha_epoch:epoch])))\n",
    "                print(np.mean(np.array(l2s[epoch-update_alpha_epoch:epoch])))\n",
    "            # plt.figure()\n",
    "            # plt.plot(range(len(losses[epoch-100:epoch])), losses[epoch-100:epoch], label='training')\n",
    "            # plt.plot(range(len(validation_loss[epoch-100:epoch])), validation_loss[epoch-100:epoch], label='validation')\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "\n",
    "            if (coherent or least_squares) and (alpha_scaling or scaling_increase_factor > 0): \n",
    "                with torch.no_grad():\n",
    "                    l1_mean = np.mean(np.array(l1s[epoch-update_alpha_epoch:epoch]))\n",
    "                    l2_mean =  np.mean(np.array(l2s[epoch-update_alpha_epoch:epoch]))\n",
    "                    alpha = l1_mean/l2_mean * alpha_scaling\n",
    "                    alpha_scaling = alpha_scaling + scaling_increase_factor\n",
    "                    if verbose: \n",
    "                        print('scaled: ', l1_mean/l2_mean)\n",
    "                        print('l1 mean: ', l1_mean)\n",
    "                        print('l2 mean: ', l2_mean)\n",
    "                        print('alpha: ', alpha)\n",
    "                        print('alpha scaling: ', alpha_scaling)\n",
    "\n",
    "        if should_schedule: \n",
    "            scheduler.step()\n",
    "\n",
    "            \n",
    "    # plotting \n",
    "    plot_start = 0\n",
    "    start_2 = 200\n",
    "    if plot_loss: \n",
    "        plt.plot(range(len(losses[plot_start:])), losses[plot_start:], label='l1 + l2')\n",
    "        plt.plot(range(len(losses[plot_start:])), validation_loss[plot_start:], label='val')\n",
    "        plt.title('l1 starting at epoch {plot_start}'.format(plot_start=plot_start))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        if coherent: \n",
    "            plt.plot(range(len(l2s[plot_start:])), l2s[plot_start:], label='l2')\n",
    "            plt.title('l2 loss starting at epoch {plot_start}'.format(plot_start=plot_start))\n",
    "            plt.legend() \n",
    "            plt.show()\n",
    "        if start_2: \n",
    "            plt.plot(range(len(losses[start_2:])-4), [(l1s[i] + l1s[i + 1] + l1s[i + 2] + l1s[i + 3] + l1s[i + 4])/5 for i in range(start_2, len(losses)-4)], label='l1 + l2')\n",
    "            plt.plot(range(len(losses[start_2:])-6), [(validation_loss[i] + validation_loss[i + 1] + validation_loss[i + 2] + validation_loss[i + 3] + validation_loss[i + 4] + validation_loss[i + 5] + validation_loss[i + 6])/7 for i in range(start_2, len(losses)-6)], label='val')\n",
    "            plt.title('l1 starting at epoch {plot_start}'.format(plot_start=start_2))\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            if coherent: \n",
    "                plt.plot(range(len(l2s[start_2:])), l2s[start_2:], label='l2')\n",
    "                plt.title('l2 loss starting at epoch {plot_start}'.format(plot_start=start_2))\n",
    "                plt.legend() \n",
    "                plt.show()\n",
    "    \n",
    "    return network, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(ts, networks, labels, starting_zone = 0): \n",
    "    \"\"\"\n",
    "    Visualizes the networks' predictions on a specific time series \n",
    "    ts: time series to visualize\n",
    "    labels: labels of the networks for plotting\n",
    "    defining each zone as 50 points just so the graphs are easier to see \n",
    "    networks and labels should have same length\n",
    "    \"\"\"\n",
    "    with torch.no_grad(): \n",
    "        truth = y_test.numpy()[:,ts]\n",
    "        start_time = starting_zone*50\n",
    "        end_time = start_time + 50\n",
    "        plt.plot(truth[start_time:end_time], label = 'truth')\n",
    "\n",
    "        for i in range(len(networks)): \n",
    "            predict_net = networks[i](X_test).numpy()[:,ts]\n",
    "\n",
    "            plt.plot(predict_net[start_time:end_time], label = labels[i])\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_RMSE(network): \n",
    "    network.lstm.eval()  \n",
    "    return calculate_RMSE(y_test.numpy(), network(X_test.to(device)).cpu().detach().numpy())\n",
    "\n",
    "\n",
    "def get_metrics(networks, verbose=False): \n",
    "    rmses = []\n",
    "    network_coherencies = [] \n",
    "    ll_losses = [] \n",
    "    #print(networks)\n",
    "    for network in networks: \n",
    "        network.lstm.eval() \n",
    "        rmse = calculate_mean_RMSE(network)\n",
    "        network_coherency = coherency_metric(network(X_test.to(device))).item() \n",
    "        ll_loss = coherency_loss(network).item()\n",
    "        if verbose: \n",
    "            print(\"RMSE: \", rmse)\n",
    "            print(\"Network coherency: \", network_coherency)\n",
    "            print(\"Last Layer Coherency Loss: \", ll_loss)\n",
    "        rmses.append(rmse)\n",
    "        network_coherencies.append(network_coherency)\n",
    "        ll_losses.append(ll_loss)\n",
    "    return rmses, network_coherencies, ll_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name): \n",
    "    torch.save(model.state_dict(), name + '.pth')\n",
    "    \n",
    "def load_model(path, should_project): \n",
    "    model = LstmNet(n_series, context_window, should_project=should_project)\n",
    "    model.load_state_dict(torch.load(path,  map_location=torch.device('cpu')))\n",
    "    model.to(device)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_baselines = True\n",
    "trained_projection = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m seed \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m) \n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trained_baselines: \n\u001b[0;32m----> 9\u001b[0m     baseline_network \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbaseline_batching_\u001b[39;49m\u001b[38;5;132;43;01m{i}\u001b[39;49;00m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     baseline_network, loss \u001b[38;5;241m=\u001b[39m train_net(\u001b[38;5;241m1000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, plot_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(path, should_project)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(path, should_project): \n\u001b[1;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m LstmNet(n_series, context_window, should_project\u001b[38;5;241m=\u001b[39mshould_project)\n\u001b[0;32m----> 6\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2022b/lib/python3.8/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2022b/lib/python3.8/site-packages/torch/serialization.py:1049\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1047\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1048\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1049\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2022b/lib/python3.8/site-packages/torch/serialization.py:1019\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1018\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1019\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2022b/lib/python3.8/site-packages/torch/serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    997\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39m_UntypedStorage)\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_untyped()\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[0;32m-> 1001\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1002\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2022b/lib/python3.8/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2022b/lib/python3.8/site-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2022b/lib/python3.8/site-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "n_trials = 5\n",
    "\n",
    "baseline_metrics = np.zeros((4, n_trials))\n",
    "baseline_networks = [] \n",
    "\n",
    "for i in range(n_trials): \n",
    "    seed = random.randint(0, 100) \n",
    "    if trained_baselines: \n",
    "        baseline_network = load_model('baseline_batching_{i}.pth'.format(i=i), False)\n",
    "    else:\n",
    "        baseline_network, loss = train_net(1000, batch_size=25, plot_loss=True, lr=0.0005)\n",
    "        save_model(baseline_network, 'baseline_batching_{i}'.format(i=i))\n",
    "        \n",
    "    rmse_baseline, network_coherency_baseline, network_loss_baseline = get_metrics([baseline_network], verbose=True)\n",
    "    validation_loss = calculate_RMSE(y_val.numpy(), baseline_network(X_val.to(device)).detach().cpu().numpy())\n",
    "    baseline_metrics[:, i] = [rmse_baseline[0], network_coherency_baseline[0], network_loss_baseline[0], validation_loss]\n",
    "    baseline_networks.append(baseline_network) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "projection_metrics = np.zeros((4, n_trials))  \n",
    "projection_networks = [] \n",
    "\n",
    "for i in range(n_trials): \n",
    "    seed = random.randint(0, 100) \n",
    "    if trained_projection: \n",
    "        projection_network = load_model('projection_batched_{i}.pth'.format(i=i), True)\n",
    "    else: \n",
    "        projection_network, loss = train_net(1000, batch_size=25, plot_loss=True, should_project=True, lr=0.00025)\n",
    "        save_model(projection_network, 'projection_batched_{i}'.format(i=i))\n",
    "        \n",
    "    rmse_projection, network_coherency_projection, network_loss_projection = get_metrics([projection_network], verbose=True)\n",
    "    validation_loss = calculate_RMSE(y_val.numpy(), projection_network(X_val.to(device)).detach().cpu().numpy())\n",
    "    projection_metrics[:, i] = [rmse_projection[0], network_coherency_projection[0], network_loss_projection[0], validation_loss]\n",
    "    projection_networks.append(rmse_projection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(baseline_metrics.mean(axis=1)) \n",
    "print(baseline_metrics.std(axis=1)) \n",
    "print(projection_metrics.mean(axis=1))\n",
    "print(projection_metrics.std(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_experiments = [0.001, 0.01, 0.1, 1, 10]\n",
    "alpha_scale_experiments = [0.05, .25, 1, 5, 20, 50]\n",
    "alpha_scale_increment_experiments = [0.1, 0.5, 1, 5, 10, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_alpha = 100\n",
    "const_alph_scale = 0\n",
    "n_trials = 5\n",
    "alpha_inc_experiments_trained = True\n",
    "\n",
    "metrics_increment = np.zeros((4, n_trials, len(alpha_scale_increment_experiments)))\n",
    "\n",
    "for i in range(n_trials):\n",
    "    print('----')\n",
    "    scaling_idx = 0 \n",
    "    for scaling_increase_factor in alpha_scale_increment_experiments: \n",
    "        if alpha_inc_experiments_trained: \n",
    "            network = load_model('scaling_increment_batched_alpha_{inc}_trial={i}.pth'.format(inc=scaling_increase_factor, i=i), False)\n",
    "        else: \n",
    "            network, loss = train_net(1000, batch_size=25, coherent=True, alpha=const_alpha, alpha_scaling=const_alph_scale, should_project=False,\n",
    "                                 scaling_increase_factor=scaling_increase_factor, \n",
    "                                 lr=0.0005/(1 + np.log(1+scaling_increase_factor/2)), plot_loss=True)\n",
    "            save_model(network, 'scaling_increment_batched_alpha_{inc}_trial={i}'.format(inc=scaling_increase_factor, i=i))\n",
    "            \n",
    "        rmse, coherency, network_loss = get_metrics([network], verbose=True)\n",
    "        validation_loss = calculate_RMSE(y_val.numpy(), network(X_val.to(device)).detach().cpu().numpy())\n",
    "        metrics_increment[:, i, scaling_idx] = [rmse[0], coherency[0], network_loss[0], validation_loss]\n",
    "        \n",
    "        scaling_idx += 1\n",
    "        \n",
    "        del network\n",
    "        gc.collect() \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print('test')\n",
    "print(metrics_increment.mean(axis=1)[0, :])\n",
    "print(metrics_increment.std(axis=1)[0, :])\n",
    "print('validation') \n",
    "print(metrics_increment.mean(axis=1)[3, :])\n",
    "print(metrics_increment.std(axis=1)[3, :])\n",
    "print('coherency') \n",
    "print(metrics_increment.mean(axis=1)[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "RMSE:  0.013936079662985651\n",
      "Network coherency:  0.006276169826664095\n",
      "Last Layer Coherency Loss:  21.2809979348533\n",
      "RMSE:  0.014533327820667259\n",
      "Network coherency:  0.006143454709253568\n",
      "Last Layer Coherency Loss:  15.918782021908308\n",
      "RMSE:  0.014723341152784723\n",
      "Network coherency:  0.005247704713978316\n",
      "Last Layer Coherency Loss:  13.391622386517092\n",
      "RMSE:  0.014877464259722611\n",
      "Network coherency:  0.0029245415809769854\n",
      "Last Layer Coherency Loss:  6.578855394506436\n",
      "RMSE:  0.013663140544910206\n",
      "Network coherency:  0.0015884262495399497\n",
      "Last Layer Coherency Loss:  3.3219806802465035\n",
      "RMSE:  0.013764176938040596\n",
      "Network coherency:  0.0014771658064856147\n",
      "Last Layer Coherency Loss:  0.15689233733275748\n",
      "----\n",
      "RMSE:  0.014160547593307773\n",
      "Network coherency:  0.006363242876805543\n",
      "Last Layer Coherency Loss:  21.23233105776967\n",
      "RMSE:  0.014412333925148893\n",
      "Network coherency:  0.005742931499046599\n",
      "Last Layer Coherency Loss:  15.913921600285818\n",
      "RMSE:  0.014398577902098034\n",
      "Network coherency:  0.005143582401872106\n",
      "Last Layer Coherency Loss:  13.33891153116626\n",
      "RMSE:  0.014546145095355137\n",
      "Network coherency:  0.003015000126801641\n",
      "Last Layer Coherency Loss:  6.519014226117687\n",
      "RMSE:  0.014005148670585846\n",
      "Network coherency:  0.00162966307244933\n",
      "Last Layer Coherency Loss:  3.345606558242103\n",
      "RMSE:  0.013791898786961684\n",
      "Network coherency:  0.001143082483716776\n",
      "Last Layer Coherency Loss:  0.21102605036573546\n",
      "----\n",
      "RMSE:  0.014161041267766216\n",
      "Network coherency:  0.006275910624243402\n",
      "Last Layer Coherency Loss:  21.31699390221867\n",
      "RMSE:  0.014111547921355485\n",
      "Network coherency:  0.005785081761247998\n",
      "Last Layer Coherency Loss:  16.094793946395217\n",
      "RMSE:  0.014326188708078553\n",
      "Network coherency:  0.005151814449807265\n",
      "Last Layer Coherency Loss:  13.304219667273154\n",
      "RMSE:  0.014772633286480347\n",
      "Network coherency:  0.0029984751839486844\n",
      "Last Layer Coherency Loss:  6.6139744146103165\n",
      "RMSE:  0.01440155723964562\n",
      "Network coherency:  0.001607451536958089\n",
      "Last Layer Coherency Loss:  3.3235700456551482\n",
      "RMSE:  0.013398095565256046\n",
      "Network coherency:  0.00017515803920819248\n",
      "Last Layer Coherency Loss:  0.1472594074738122\n",
      "----\n",
      "RMSE:  0.014025927323084874\n",
      "Network coherency:  0.006244669070294276\n",
      "Last Layer Coherency Loss:  21.13739443162771\n",
      "RMSE:  0.014058774923602285\n",
      "Network coherency:  0.005863793812824033\n",
      "Last Layer Coherency Loss:  15.953625373331484\n",
      "RMSE:  0.015213866150872234\n",
      "Network coherency:  0.005299374175830592\n",
      "Last Layer Coherency Loss:  13.36140364463338\n",
      "RMSE:  0.014502908212218368\n",
      "Network coherency:  0.0029457395743538893\n",
      "Last Layer Coherency Loss:  6.457621928115279\n",
      "RMSE:  0.014489947546213244\n",
      "Network coherency:  0.0014745535967512727\n",
      "Last Layer Coherency Loss:  3.022507348218109\n",
      "RMSE:  0.013605459328473147\n",
      "Network coherency:  0.00031397763465295243\n",
      "Last Layer Coherency Loss:  0.18013757139363296\n",
      "test\n",
      "[0.0140709  0.014279   0.01466549 0.01467479 0.01413995 0.01363991]\n",
      "[9.53430701e-05 1.99373932e-04 3.50153750e-04 1.55517704e-04\n",
      " 3.30323813e-04 1.56687534e-04]\n",
      "validation\n",
      "[0.00868301 0.00865824 0.00892856 0.00850059 0.00803928 0.00782088]\n",
      "[2.76636224e-04 1.36185552e-04 3.22118997e-04 1.94231001e-04\n",
      " 7.86087659e-05 5.64408307e-05]\n",
      "coherency\n",
      "[0.00629    0.00588382 0.00521062 0.00297094 0.00157502 0.00077735]\n"
     ]
    }
   ],
   "source": [
    "const_alpha = 100\n",
    "const_alph_scale = 0\n",
    "n_trials = 4\n",
    "alpha_inc_experiments_trained = True\n",
    "\n",
    "metrics_increment = np.zeros((4, n_trials, len(alpha_scale_increment_experiments)))\n",
    "\n",
    "for i in range(n_trials):\n",
    "    print('----')\n",
    "    scaling_idx = 0 \n",
    "    for scaling_increase_factor in alpha_scale_increment_experiments: \n",
    "        if alpha_inc_experiments_trained: \n",
    "            network = load_model('scaling_increment_batched_{inc}_trial={i}.pth'.format(inc=scaling_increase_factor, i=i), False)\n",
    "        else: \n",
    "            network, loss = train_net(1000, batch_size=25, coherent=True, alpha=const_alpha, alpha_scaling=const_alph_scale, should_project=False,\n",
    "                                 scaling_increase_factor=scaling_increase_factor, \n",
    "                                 lr=0.0005/(1 + np.log(1+scaling_increase_factor/2)), plot_loss=True)\n",
    "            save_model(network, 'scaling_increment_batched_alpha_trial={i}'.format(inc=scaling_increase_factor, i=i))\n",
    "            \n",
    "        rmse, coherency, network_loss = get_metrics([network], verbose=True)\n",
    "        validation_loss = calculate_RMSE(y_val.numpy(), network(X_val.to(device)).detach().cpu().numpy())\n",
    "        metrics_increment[:, i, scaling_idx] = [rmse[0], coherency[0], network_loss[0], validation_loss]\n",
    "        \n",
    "        scaling_idx += 1\n",
    "        \n",
    "        del network\n",
    "        gc.collect() \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print('test')\n",
    "print(metrics_increment.mean(axis=1)[0, :])\n",
    "print(metrics_increment.std(axis=1)[0, :])\n",
    "print('validation') \n",
    "print(metrics_increment.mean(axis=1)[3, :])\n",
    "print(metrics_increment.std(axis=1)[3, :])\n",
    "print('coherency') \n",
    "print(metrics_increment.mean(axis=1)[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "[0.0140709  0.014279   0.01466549 0.01467479 0.01413995 0.01363991]\n",
      "[9.53430701e-05 1.99373932e-04 3.50153750e-04 1.55517704e-04\n",
      " 3.30323813e-04 1.56687534e-04]\n",
      "validation\n",
      "[0.00868301 0.00865824 0.00892856 0.00850059 0.00803928 0.00782088]\n",
      "[2.76636224e-04 1.36185552e-04 3.22118997e-04 1.94231001e-04\n",
      " 7.86087659e-05 5.64408307e-05]\n",
      "coherency\n",
      "[0.00629    0.00588382 0.00521062 0.00297094 0.00157502 0.00077735]\n",
      "[4.41848288e-05 1.56052908e-04 6.55833669e-05 3.70383445e-05\n",
      " 5.98140778e-05 5.47916855e-04]\n"
     ]
    }
   ],
   "source": [
    "print('test')\n",
    "print(metrics_increment.mean(axis=1)[0, :])\n",
    "print(metrics_increment.std(axis=1)[0, :])\n",
    "print('validation') \n",
    "print(metrics_increment.mean(axis=1)[3, :])\n",
    "print(metrics_increment.std(axis=1)[3, :])\n",
    "print('coherency') \n",
    "print(metrics_increment.mean(axis=1)[1, :])\n",
    "print(metrics_increment.std(axis=1)[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory(): \n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    r = torch.cuda.memory_reserved(0)\n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    print(t, r, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_alpha = 0\n",
    "const_alph_scale = 0\n",
    "n_trials = 5\n",
    "proj_inc_trained = True\n",
    "\n",
    "metrics_project_increment = np.zeros((3, n_trials, len(alpha_scale_increment_experiments)))\n",
    "#networks_project_increment = [[] for i in range(n_trials)]\n",
    "\n",
    "for i in range(n_trials):  \n",
    "    scaling_idx = 0 \n",
    "    for scaling_increase_factor in alpha_scale_increment_experiments: \n",
    "        if proj_inc_trained: \n",
    "            network = load_model('projection_inc_batched_{inc}_trial={i}.pth.pth'.format(inc=scaling_increase_factor, i=i), True)\n",
    "        else: \n",
    "            network, loss = train_net(1000, batch_size=25, coherent=True, alpha=const_alpha, alpha_scaling=const_alph_scale, should_project=True,\n",
    "                                 scaling_increase_factor=scaling_increase_factor, \n",
    "                                 lr=0.005/(1 + np.log(1+scaling_increase_factor/4)), plot_loss=True)\n",
    "            save_model(network, 'projection_inc_batched_{inc}_trial={i}.pth'.format(inc=scaling_increase_factor, i=i))\n",
    "            \n",
    "        rmse, coherency, network_loss = get_metrics([network], verbose=True)\n",
    "        validation_loss = calculate_RMSE(y_val.numpy(), network(X_val.to(device)).detach().cpu().numpy())\n",
    "        metrics_project_increment[0, i, scaling_idx] = rmse[0] \n",
    "        metrics_project_increment[1, i, scaling_idx] = validation_loss\n",
    "        metrics_project_increment[2, i, scaling_idx] = coherency[0]\n",
    "        #networks_project_increment[i].append(network)\n",
    "        \n",
    "        scaling_idx += 1\n",
    "        \n",
    "metrics_project_increment.mean(axis=1), metrics_project_increment.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test')\n",
    "print(metrics_project_increment.mean(axis=1)[0, :])\n",
    "print(metrics_project_increment.std(axis=1)[0, :])\n",
    "print('validation') \n",
    "print(metrics_project_increment.mean(axis=1)[1, :])\n",
    "print(metrics_project_increment.std(axis=1)[1, :])\n",
    "print('coherency') \n",
    "print(metrics_project_increment.mean(axis=1)[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.00801964797814301\n",
      "Network coherency:  0.01163829196233241\n",
      "Last Layer Coherency Loss:  2.338877797375149\n",
      "RMSE:  0.008782075902033197\n",
      "Network coherency:  0.0215207585173377\n",
      "Last Layer Coherency Loss:  0.5617629265520871\n",
      "RMSE:  0.00839498508463038\n",
      "Network coherency:  0.0012960302133732137\n",
      "Last Layer Coherency Loss:  2.0939197430738234\n",
      "RMSE:  0.00976812328485328\n",
      "Network coherency:  0.012878966208054704\n",
      "Last Layer Coherency Loss:  1.5098113205610646\n",
      "RMSE:  0.009436652908927727\n",
      "Network coherency:  0.0006336814332317253\n",
      "Last Layer Coherency Loss:  0.3715310870064088\n",
      "RMSE:  0.09147431084699824\n",
      "Network coherency:  0.565064448941232\n",
      "Last Layer Coherency Loss:  8.360082546410988\n",
      "RMSE:  0.009642978802497147\n",
      "Network coherency:  0.0042825139101230255\n",
      "Last Layer Coherency Loss:  3.3154933111311413\n",
      "RMSE:  0.009441054132609837\n",
      "Network coherency:  0.00037466660817381915\n",
      "Last Layer Coherency Loss:  0.5978347437472771\n",
      "RMSE:  0.007578881365072924\n",
      "Network coherency:  0.00019335832319822662\n",
      "Last Layer Coherency Loss:  0.3464166781834134\n",
      "RMSE:  0.010356620142207245\n",
      "Network coherency:  0.03038597356749519\n",
      "Last Layer Coherency Loss:  0.423324944681449\n",
      "RMSE:  0.0760169760735473\n",
      "Network coherency:  0.4735439531687642\n",
      "Last Layer Coherency Loss:  7.6196171423817445\n",
      "RMSE:  0.026052742349859336\n",
      "Network coherency:  0.15413385957009135\n",
      "Last Layer Coherency Loss:  3.5360416037182594\n",
      "RMSE:  0.009468217453513327\n",
      "Network coherency:  0.0006412426425694221\n",
      "Last Layer Coherency Loss:  0.996689158605891\n",
      "RMSE:  0.00932316171359591\n",
      "Network coherency:  0.036366193059347206\n",
      "Last Layer Coherency Loss:  5.112642149872371\n",
      "RMSE:  0.010417102800094596\n",
      "Network coherency:  0.01735709046705398\n",
      "Last Layer Coherency Loss:  0.2369934383093804\n",
      "RMSE:  0.027630383270440376\n",
      "Network coherency:  0.1334899365670216\n",
      "Last Layer Coherency Loss:  8.566047548224535\n",
      "RMSE:  0.00949823443640414\n",
      "Network coherency:  0.0001868732389709045\n",
      "Last Layer Coherency Loss:  0.09348228705145609\n",
      "RMSE:  0.009451028903325259\n",
      "Network coherency:  0.00107684427943914\n",
      "Last Layer Coherency Loss:  1.0912109516255677\n",
      "RMSE:  0.007524940947723786\n",
      "Network coherency:  0.001374651107300598\n",
      "Last Layer Coherency Loss:  2.8970901082680864\n",
      "RMSE:  0.010751715064370617\n",
      "Network coherency:  0.0005824214943271209\n",
      "Last Layer Coherency Loss:  0.47824743025803074\n",
      "RMSE:  0.010393955131448564\n",
      "Network coherency:  0.010793311011670519\n",
      "Last Layer Coherency Loss:  7.666291142219584\n",
      "RMSE:  0.009934839764205785\n",
      "Network coherency:  0.015463459091377108\n",
      "Last Layer Coherency Loss:  2.450954088508837\n",
      "RMSE:  0.009457030255309877\n",
      "Network coherency:  0.0009683427406610209\n",
      "Last Layer Coherency Loss:  1.7925383860137334\n",
      "RMSE:  0.009992691848800847\n",
      "Network coherency:  0.021053353089251246\n",
      "Last Layer Coherency Loss:  0.8267593240538907\n",
      "RMSE:  0.010039378604166937\n",
      "Network coherency:  0.0025279196576026165\n",
      "Last Layer Coherency Loss:  0.6455281411150945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[4.27070547e-02, 1.27821743e-02, 9.24246317e-03, 8.83755983e-03,\n",
       "         1.02002939e-02],\n",
       "        [2.38905988e-01, 3.91174929e-02, 8.71425297e-04, 1.43733044e-02,\n",
       "         1.02974173e-02],\n",
       "        [6.91018324e+00, 1.99154684e+00, 1.31443860e+00, 2.13854392e+00,\n",
       "         4.31125008e-01],\n",
       "        [5.12316024e-02, 1.53776691e-02, 8.09651489e-03, 7.52034372e-03,\n",
       "         7.17072020e-03]]),\n",
       " array([[3.45324622e-02, 6.64612499e-03, 4.23830431e-04, 1.07175812e-03,\n",
       "         4.43745555e-04],\n",
       "        [2.35045893e-01, 5.80120537e-02, 3.26077455e-04, 1.34207236e-02,\n",
       "         1.18450252e-02],\n",
       "        [2.31585508e+00, 1.41395081e+00, 5.47811397e-01, 1.71746652e+00,\n",
       "         1.33782337e-01],\n",
       "        [3.31238920e-02, 6.94478865e-03, 1.23023209e-03, 1.33536092e-03,\n",
       "         5.94192240e-04]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_alpha = 0\n",
    "const_alph_scale = 0\n",
    "n_trials = 5\n",
    "alpha_inc_experiments_trained = True\n",
    "\n",
    "metrics_increment = np.zeros((4, n_trials, len(alpha_experiments)))\n",
    "\n",
    "for i in range(n_trials):  \n",
    "    scaling_idx = 0 \n",
    "    for alpha in alpha_experiments: \n",
    "        if alpha_inc_experiments_trained: \n",
    "            network = load_model('alpha_{alpha}_trial={i}.pth'.format(alpha=alpha, i=i), False)\n",
    "        else: \n",
    "            network, loss = train_net(1000, batch_size=25, coherent=True, alpha=alpha, alpha_scaling=const_alph_scale, should_project=False,\n",
    "                                 scaling_increase_factor=5, \n",
    "                                 lr=0.005/(1 + np.log(1+alpha)), plot_loss=True)\n",
    "            save_model(network, 'alpha_{alpha}_trial={i}'.format(alpha=alpha, i=i))\n",
    "            \n",
    "        rmse, coherency, network_loss = get_metrics([network], verbose=True)\n",
    "        validation_loss = calculate_RMSE(y_val.numpy(), network(X_val.to(device)).detach().cpu().numpy())\n",
    "        metrics_increment[:, i, scaling_idx] = [rmse[0], coherency[0], network_loss[0], validation_loss]\n",
    "        \n",
    "        scaling_idx += 1\n",
    "\n",
    "metrics_increment.mean(axis=1), metrics_increment.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "[0.04270705 0.01278217 0.00924246 0.00883756 0.01020029]\n",
      "[0.03453246 0.00664612 0.00042383 0.00107176 0.00044375]\n",
      "validation\n",
      "[0.0512316  0.01537767 0.00809651 0.00752034 0.00717072]\n",
      "[0.03312389 0.00694479 0.00123023 0.00133536 0.00059419]\n",
      "coherency\n",
      "[0.23890599 0.03911749 0.00087143 0.0143733  0.01029742]\n",
      "[0.23504589 0.05801205 0.00032608 0.01342072 0.01184503]\n"
     ]
    }
   ],
   "source": [
    "print('test')\n",
    "print(metrics_increment.mean(axis=1)[0, :])\n",
    "print(metrics_increment.std(axis=1)[0, :])\n",
    "print('validation') \n",
    "print(metrics_increment.mean(axis=1)[3, :])\n",
    "print(metrics_increment.std(axis=1)[3, :])\n",
    "print('coherency') \n",
    "print(metrics_increment.mean(axis=1)[1, :])\n",
    "print(metrics_increment.std(axis=1)[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_alpha = 0\n",
    "const_alph_scale = 0\n",
    "\n",
    "networks_scale_increment = [train_net(10000, coherent=True, alpha=const_alpha, alpha_scaling=const_alph_scale, \n",
    "                            scaling_increase_factor=scaling_increase_factor, lr=0.005/(1 + np.log(1 + scaling_increase_factor/4)), \n",
    "                                      plot_loss=True) for scaling_increase_factor in [10]]\n",
    "\n",
    "get_metrics(networks_scale_increment, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rmses_if = np.mean(metrics_increment[0], axis=0)\n",
    "std_rmses_if = np.std(metrics_increment[0], axis=0)\n",
    "\n",
    "print(mean_rmses_if)\n",
    "print(std_rmses_if) \n",
    "\n",
    "mean_network_coherencies_if = np.mean(metrics_increment[1], axis=0)\n",
    "std_network_coherencies_if = np.std(metrics_increment[1], axis=0)\n",
    "\n",
    "mean_ll_losses_if = np.mean(metrics_increment[2], axis=0)\n",
    "std_ll_losses_if = 2*np.std(metrics_increment[2], axis=0)\n",
    "\n",
    "print(mean_network_coherencies_if)\n",
    "print(std_network_coherencies_if) \n",
    "\n",
    "# Calculate mean and std for baseline and projection metrics\n",
    "mean_metrics_baseline = np.mean(baseline_metrics, axis=1)\n",
    "std_metrics_baseline = 2*np.std(baseline_metrics, axis=1)\n",
    "\n",
    "mean_metrics_projection = np.mean(projection_metrics, axis=1)\n",
    "std_metrics_projection = 2*np.std(projection_metrics, axis=1)\n",
    "\n",
    "print(mean_metrics_baseline)\n",
    "print(std_metrics_baseline)\n",
    "print(mean_metrics_projection)\n",
    "print(std_metrics_projection) \n",
    "\n",
    "# Plotting\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(6, 10))\n",
    "\n",
    "# RMSE plot with error bars\n",
    "ax1.set_title('RMSE vs alpha scaling increment')\n",
    "ax1.errorbar(alpha_scale_increment_experiments, mean_rmses_if, yerr=std_rmses_if, fmt='o', label='Incremental')\n",
    "ax1.axhline(mean_metrics_baseline[0], color='red', label='Baseline', linestyle='--')\n",
    "ax1.axhline(mean_metrics_projection[0], color='blue', label='Projection', linestyle='--')\n",
    "ax1.fill_between([min(alpha_scale_increment_experiments), max(alpha_scale_increment_experiments)], mean_metrics_baseline[0]-std_metrics_baseline[0], mean_metrics_baseline[0]+std_metrics_baseline[0], color='red', alpha=0.2)\n",
    "ax1.fill_between([min(alpha_scale_increment_experiments), max(alpha_scale_increment_experiments)], mean_metrics_projection[0]-std_metrics_projection[0], mean_metrics_projection[0]+std_metrics_projection[0], color='blue', alpha=0.2)\n",
    "ax1.set_ylabel('RMSE')\n",
    "ax1.set_xlabel('Alpha')\n",
    "ax1.legend()\n",
    "\n",
    "# Network coherency plot with error bars\n",
    "ax2.set_title('Coherency on data vs alpha, incremental')\n",
    "ax2.errorbar(alpha_scale_increment_experiments, mean_network_coherencies_if, yerr=std_network_coherencies_if, fmt='o')\n",
    "ax2.set_ylabel('Coherency on data')\n",
    "ax2.set_xlabel('Alpha')\n",
    "\n",
    "# Last layer coherency plot with error bars\n",
    "ax3.errorbar(alpha_scale_increment_experiments, mean_ll_losses_if, yerr=std_ll_losses_if, fmt='o')\n",
    "ax3.set_ylabel('Last layer coherency')\n",
    "ax3.set_xlabel('Alpha')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_alpha = 0\n",
    "const_alph_scale = 0\n",
    "\n",
    "networks_project = [train_net(6000, coherent=True, alpha=0, alpha_scaling=0, should_project=True, plot_loss=True,\n",
    "                            scaling_increase_factor=scaling_increase_factor, lr=0.005/(1 + np.log(1+scaling_increase_factor/4))) for scaling_increase_factor in alpha_scale_increment_experiments]\n",
    "\n",
    "get_metrics(networks_project, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(6, 10))\n",
    "ax1.set_title('metrics vs alpha scaling increment with projection')\n",
    "ax1.scatter(alpha_scale_experiments, rmses_if)\n",
    "ax1.axhline(rmse_baseline, color='red', label='baseline')\n",
    "ax1.axhline(rmse_projection, color='green', label='projection')\n",
    "ax1.set_ylabel('rmse')\n",
    "ax1.set_xlabel('alpha')\n",
    "ax1.legend()\n",
    "#ax2.set_title('coherency on data vs alpha, no scaling and no scaling increment')\n",
    "ax2.scatter(alpha_scale_experiments, network_coherencies_if)\n",
    "ax2.set_ylabel('coherency on data')\n",
    "ax2.set_xlabel('alpha')\n",
    "#ax3.set_title('last layer coherency vs alpha, no scaling and no scaling increment')\n",
    "ax3.scatter(alpha_scale_experiments, ll_losses_if)\n",
    "ax3.set_ylabel('last layer coherency')\n",
    "ax3.set_xlabel('alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network, losses = train_net(1000, coherent=False) \n",
    "#network_coherent, losses_coherent = train_net(1000, coherent=True, alpha=0)\n",
    "#network_coherent_high_scaling, losses_coherent_high_scaling = train_net(1000, coherent=True, alpha=0.25, alpha_scaling=1)\n",
    "network_projection, losses_projection = train_net(5000, should_project=True)\n",
    "#network_coherent_and_projecting, losses_projection_high_scaling = train_net(1000, coherent=True, alpha=0.5, alpha_scaling=1, should_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(losses_projection[100:])), losses_projection[100:], label='projection')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "#plt.plot(range(len(losses_coherent[101:])), losses_coherent[101:], label='coherent')\n",
    "#plt.plot(range(len(losses_coherent_high_scaling[101:])), losses_coherent_high_scaling[101:], label='high scaling')\n",
    "#plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_projection = calculate_mean_RMSE(network_projection)\n",
    "rmse_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_projection = 0.0032 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_baseline, losses_baseline = train_net(2000, coherent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_baseline = calculate_mean_RMSE(network_baseline)\n",
    "rmse_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(18, 10))\n",
    "fig.suptitle('Labour Dataset')\n",
    "\n",
    "# First Set of Data\n",
    "axs[0, 0].set_title('Alpha Experiments (No Scaling and No Scaling Increment)')\n",
    "axs[0, 0].scatter(alpha_experiments, rmses)\n",
    "axs[0, 0].set_ylabel('rmse')\n",
    "axs[0, 0].set_xlabel('alpha')\n",
    "axs[0, 0].axhline(rmse_baseline, color='red', label='baseline')\n",
    "axs[0, 0].axhline(rmse_projection, color='green', label='projection')\n",
    "axs[0, 0].legend()\n",
    "\n",
    "axs[1, 0].scatter(alpha_experiments, network_coherencies)\n",
    "axs[1, 0].set_ylabel('coherency on data')\n",
    "axs[1, 0].set_xlabel('alpha')\n",
    "axs[1, 0].axhline(network_coherency_baseline, color='red', label='baseline')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "axs[2, 0].scatter(alpha_experiments, ll_losses)\n",
    "axs[2, 0].set_ylabel('last layer coherency')\n",
    "axs[2, 0].set_xlabel('alpha')\n",
    "\n",
    "# Second Set of Data\n",
    "axs[0, 1].set_title('Alpha Scaling Experiments (Constant alpha = 0)')\n",
    "axs[0, 1].scatter(alpha_scale_experiments, rmses_s)\n",
    "axs[0, 1].axhline(rmse_baseline, color='red', label='baseline')\n",
    "axs[0, 1].axhline(rmse_projection, color='green', label='projection')\n",
    "axs[0, 1].set_ylabel('rmse')\n",
    "axs[0, 1].set_xlabel('alpha scaling')\n",
    "axs[0, 1].legend()\n",
    "\n",
    "axs[1, 1].scatter(alpha_scale_experiments, network_coherencies_s)\n",
    "axs[1, 1].set_ylabel('coherency on data')\n",
    "axs[1, 1].set_xlabel('alpha scaling')\n",
    "axs[1, 1].axhline(network_coherency_baseline, color='red', label='baseline')\n",
    "axs[1, 1].legend()\n",
    "\n",
    "axs[2, 1].scatter(alpha_scale_experiments, ll_losses_s)\n",
    "axs[2, 1].set_ylabel('last layer coherency')\n",
    "axs[2, 1].set_xlabel('alpha scaling')\n",
    "\n",
    "# Third Set of Data\n",
    "axs[0, 2].set_title('Scaling Increment Experiments (Constant alpha = 0, scaling = 0)')\n",
    "axs[0, 2].scatter(alpha_scale_increment_experiments, rmses_if)\n",
    "axs[0, 2].axhline(rmse_baseline, color='red', label='baseline')\n",
    "axs[0, 2].axhline(rmse_projection, color='green', label='projection')\n",
    "axs[0, 2].set_ylabel('rmse')\n",
    "axs[0, 2].set_xlabel('alpha increment')\n",
    "axs[0, 2].legend()\n",
    "\n",
    "axs[1, 2].scatter(alpha_scale_increment_experiments, network_coherencies_if)\n",
    "axs[1, 2].set_ylabel('coherency on data')\n",
    "axs[1, 2].set_xlabel('alpha increment')\n",
    "axs[1, 2].axhline(network_coherency_baseline, color='red', label='baseline')\n",
    "axs[1, 2].legend()\n",
    "\n",
    "axs[2, 2].scatter(alpha_scale_increment_experiments, ll_losses_if)\n",
    "axs[2, 2].set_ylabel('last layer coherency')\n",
    "axs[2, 2].set_xlabel('alpha increment')\n",
    "\n",
    "axs[0,0].set_xscale('log')\n",
    "axs[0,1].set_xscale('log')\n",
    "axs[0,2].set_xscale('log')\n",
    "axs[1,0].set_xscale('log')\n",
    "axs[1,1].set_xscale('log')\n",
    "axs[1,2].set_xscale('log')\n",
    "axs[2,0].set_xscale('log')\n",
    "axs[2,1].set_xscale('log')\n",
    "axs[2,2].set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('parameter_experiments_traffic.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_alpha = 0\n",
    "const_alph_scale = 0\n",
    "\n",
    "networks_increment_scaled = [train_net(4000, coherent=True, alpha=0, alpha_scaling=0, should_project=True,\n",
    "                            scaling_increase_factor=scaling_increase_factor + 0.1, lr=0.005/(1 + np.log(1+scaling_increase_factor))) for scaling_increase_factor in alpha_scale_experiments]\n",
    "\n",
    "get_metrics(networks_increment_scaled, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement a function that chooses alpha based on the best training data and hopefully show that the selected alpha also performs well on test data\n",
    "\n",
    "def test_best_alpha(networks):\n",
    "\n",
    "    train_rmses = [] \n",
    "    test_rmses = [] \n",
    "\n",
    "    for network, _ in networks: \n",
    "\n",
    "        network.lstm.eval() \n",
    "        train_rmse = calculate_RMSE(y_val.numpy(), network(X_val.to(device)).detach().cpu().numpy())\n",
    "        test_rmse = calculate_RMSE(y_test.numpy(), network(X_test.to(device)).detach().cpu().numpy())\n",
    "\n",
    "        train_rmses.append(train_rmse)\n",
    "        test_rmses.append(test_rmse)\n",
    "\n",
    "    return train_rmses, test_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmses, test_rmses = test_best_alpha(networks_scale_increment)\n",
    "#train_rmses_scaled, test_rmses_scaled = test_best_alpha(networks_increment_scaled)\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(8, 6))  # Adjust the figure size as needed\n",
    "plt.scatter(train_rmses, test_rmses)\n",
    "\n",
    "plt.axhline(rmse_projection, color='green', label='projection')\n",
    "plt.axhline(rmse_baseline, color='red', label='baseline')\n",
    "\n",
    "# Annotate each point with its label\n",
    "for i, label in enumerate(alpha_scale_increment_experiments):\n",
    "    plt.annotate(label, (train_rmses[i], test_rmses[i]), textcoords=\"offset points\", xytext=(0, 5), ha='center')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Test RMSE vs. Validation RMSE. Labels are Alpha Scaling Increment Values')\n",
    "plt.xlabel('Validation RMSE')\n",
    "plt.ylabel('Test RMSE')\n",
    "\n",
    "# # Set custom axis limits\n",
    "# plt.xlim(0.0010, 0.0013)\n",
    "# plt.ylim(0.004, 0.0055)\n",
    "\n",
    "# Show the plot\n",
    "plt.legend() \n",
    "plt.savefig('val_traffic.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_best_alpha(networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses for learning\n",
    "#plt.plot(range(len(losses[100:])), losses[100:], label='base')\n",
    "plt.plot(range(len(losses_projection[100:1000])), losses_projection_high_scaling[100:1000], label='projection')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(range(len(losses_coherent[101:])), losses_coherent[101:], label='coherent')\n",
    "plt.plot(range(len(losses_coherent_high_scaling[101:])), losses_coherent_high_scaling[101:], label='high scaling')\n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the real coherency of each network we trained\n",
    "print(\"baseline network coherency\", coherency_metric(network(X_test)).item())\n",
    "print(\"coherent network coherency\", coherency_metric(network_coherent(X_test)).item())\n",
    "print(\"coherent network coherency (high scaling)\", coherency_metric(network_coherent_high_scaling(X_test)).item())\n",
    "#print(\"projection network coherency\", coherency_metric(network_projection(X_test)).item())\n",
    "#print(\"both coherency\", coherency_metric(network_coherent_and_projecting(X_test)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 20\n",
    "\n",
    "def calculate_mean_RMSE(network, n_iters=n_iters): \n",
    "    errs = np.zeros((n_iters, )) \n",
    "    for i in range(n_iters): \n",
    "        errs[i] = calculate_RMSE(y_test.numpy(), network(X_test).detach().numpy())\n",
    "    return np.mean(errs)\n",
    "\n",
    "print(\"RMSE Baseline:\", calculate_mean_RMSE(network))\n",
    "print(\"RMSE Coherent:\", calculate_mean_RMSE(network_coherent))\n",
    "print(\"RMSE Coherent (high scaling):\", calculate_mean_RMSE(network_coherent_high_scaling))\n",
    "print(\"RMSE Projection:\", calculate_mean_RMSE(network_projection))\n",
    "print(\"RMSE Both:\", calculate_mean_RMSE(network_coherent_and_projecting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WMAPE Baseline:\", calculate_wmape(y_test.numpy(), network(X_test).detach().numpy()))\n",
    "print(\"WMAPE Coherent:\", calculate_wmape(y_test.numpy(), network_coherent(X_test).detach().numpy()))\n",
    "print(\"WMAPE Coherent (high scaling):\", calculate_wmape(y_test.numpy(), network_coherent_high_scaling(X_test).detach().numpy()))\n",
    "print(\"WMAPE Projection:\", calculate_wmape(y_test.numpy(), network_projection(X_test).detach().numpy()))\n",
    "print(\"WMAPE Both:\", calculate_wmape(y_test.numpy(), network_coherent_and_projecting(X_test).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last Layer Coherency Loss Baseline:\", coherency_loss(network).item())\n",
    "print(\"Last Layer Coherency Loss Coherent:\", coherency_loss(network_coherent).item())\n",
    "print(\"Last Layer Coherency Loss Coherent (high scaling):\", coherency_loss(network_coherent_high_scaling).item())\n",
    "print(\"Last Layer Coherency Loss Projection:\", coherency_loss(network_projection).item())\n",
    "print(\"Last Layer Coherency Loss Both:\", coherency_loss(network_coherent_and_projecting).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training 'least squares loss' networks \n",
    "network_ls, loss_ls = train_net(500, least_squares=True, alpha=0.5, alpha_scaling=1)\n",
    "network_ls_high_scaling, loss_ls_high_scaling = train_net(500, least_squares=True, alpha=0.5, alpha_scaling=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the real coherency of each network we trained\n",
    "print(\"MSE_loss network coherency\", coherency_metric(network_ls(X_test)).item())\n",
    "print(\"MSE_loss high scaling network coherency\", coherency_metric(network_ls_high_scaling(X_test)).item())\n",
    "print(\"MSE_loss and project coherency\", coherency_metric(network_ls_and_project(X_test)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the real coherency of each network we trained\n",
    "print(\"baseline network RMSE\", calculate_RMSE(y_test.numpy(), network_ls(X_test).detach().numpy()))\n",
    "print(\"coherent network RMSE\", calculate_RMSE(y_test.numpy(), network_ls_high_scaling(X_test).detach().numpy()))\n",
    "print(\"coherent network coherency (high scaling) RMSE\", calculate_RMSE(y_test.numpy(), network_ls_and_project(X_test).detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last Layer Coherency Loss Coherent:\", coherency_loss(network_ls).item())\n",
    "print(\"Last Layer Coherency Loss Coherent (high scaling):\", coherency_loss(network_ls_high_scaling).item())\n",
    "print(\"Last Layer Coherency Loss Projection:\", coherency_loss(network_projection).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(0, [network, network_coherent, network_projection], ['baseline', 'coherent loss', 'projection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agg_levels = np.unique([torch.sum(aggregation_mat[ts,:]).item() for ts in range(len(aggregation_mat))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agg_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code plots the error \n",
    "\n",
    "aggregation_level = all_agg_levels[0]\n",
    "aggregation_amounts = []\n",
    "errs_baseline = [] \n",
    "errs_coherent = []\n",
    "for ts in range(len(aggregation_mat)):\n",
    "    agg_level = torch.sum(aggregation_mat[ts,:]).item()\n",
    "    if agg_level == aggregation_level: \n",
    "        err_baseline = torch.norm(network(X_test)[:,ts] - y_test[:,ts]).item() / len(X_test)\n",
    "        err_coherent = torch.norm(network_coherent(X_test)[:,ts] - y_test[:,ts]).item() / len(X_test)\n",
    "\n",
    "        aggregation_amounts.append(agg_level)\n",
    "        errs_baseline.append(err_baseline)\n",
    "        errs_coherent.append(err_coherent)\n",
    "\n",
    "plt.hist([errs_baseline, errs_coherent], label = ['projection', 'coherent'])\n",
    "\n",
    "print(\"Baseline:\", np.mean(errs_baseline))\n",
    "print(\"Coherent:\", np.mean(errs_coherent))\n",
    "\n",
    "plt.xlabel('|y_pred - y|/N')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
